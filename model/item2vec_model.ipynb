{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境設定\n",
    "\n",
    "参照: https://github.com/oreilly-japan/RecommenderSystems/blob/main/chapter5/colab/Item2vec.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# データのDL，解凍，必要パッケージをインストール\n",
    "\n",
    "# download and unzip dataset\n",
    "!wget -nc --no-check-certificate https://files.grouplens.org/datasets/movielens/ml-10m.zip -P ../data/\n",
    "!unzip -n data/ml-10m.zip -d ../data/\n",
    "# install required packages\n",
    "!pip install -r ../env_config/requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# ファイルパス\n",
    "DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "# 学習ログ出力設定\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_users=69878, unique_movies=10677\n"
     ]
    }
   ],
   "source": [
    "# 授業ではユーザー数を1000に絞っていたが，本課題ではユーザー数を絞らずにモデルを学習することとする．\n",
    "\n",
    "# movieIDとタイトル名のみ使用\n",
    "m_cols = ['movie_id', 'title', 'genre']\n",
    "movies = pd.read_csv(f'{DIR}/../data/ml-10M100K/movies.dat', names=m_cols, sep='::' , encoding='latin-1', engine='python')\n",
    "\n",
    "# genreをlist形式で保持する\n",
    "movies['genre'] = movies.genre.apply(lambda x:x.split('|'))\n",
    "\n",
    "# ユーザが付与した映画のタグ情報の読み込み\n",
    "t_cols = ['user_id', 'movie_id', 'tag', 'timestamp']\n",
    "user_tagged_movies = pd.read_csv(f'{DIR}/../data/ml-10M100K/tags.dat', names=t_cols, sep='::', engine='python')\n",
    "\n",
    "# tagを小文字にする\n",
    "user_tagged_movies['tag'] = user_tagged_movies['tag'].str.lower()\n",
    "\n",
    "# tagを映画ごとにlist形式で保持する\n",
    "movie_tags = user_tagged_movies.groupby('movie_id').agg({'tag':list})\n",
    "\n",
    "# タグ情報を結合する\n",
    "movies = movies.merge(movie_tags, on='movie_id', how='left')\n",
    "\n",
    "# 評価値データの読み込み\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv(f'{DIR}/../data/ml-10M100K/ratings.dat', names=r_cols, sep='::', engine='python')\n",
    "\n",
    "# # データ量が多いため、ユーザー数を1000に絞って、試していく -> use all\n",
    "# valid_user_ids = sorted(ratings.user_id.unique())[:1000]\n",
    "# ratings = ratings[ratings[\"user_id\"].isin(valid_user_ids)]\n",
    "\n",
    "# 映画のデータと評価のデータを結合する\n",
    "movielens = ratings.merge(movies, on='movie_id')\n",
    "# print(movielens)\n",
    "print(f'unique_users={len(movielens.user_id.unique())}, unique_movies={len(movielens.movie_id.unique())}')\n",
    "\n",
    "# 学習用とテスト用にデータを分割する\n",
    "# 各ユーザの直近の５件の映画を評価用に使い、それ以外を学習用とする\n",
    "# まずは、それぞれのユーザが評価した映画の順序を計算する\n",
    "# 直近付与した映画から順番を付与していく(1始まり)\n",
    "\n",
    "movielens['timestamp_rank'] = movielens.groupby(\n",
    "    'user_id')['timestamp'].rank(ascending=False, method='first')\n",
    "movielens_train = movielens[movielens['timestamp_rank'] > 5]\n",
    "movielens_test = movielens[movielens['timestamp_rank']<= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item2vecのインプットに使うデータの生成\n",
    "item2vec_data = []\n",
    "movielens_train_high_rating = movielens_train[movielens_train.rating >= 4]\n",
    "for user_id, data in movielens_train_high_rating.groupby(\"user_id\"):\n",
    "    # 評価された順に並び替える\n",
    "    # item2vecではwindowというパラメータがあり、itemの評価された順番も重要な要素となる\n",
    "    item2vec_data.append(data.sort_values(\"timestamp\")[\"movie_id\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習パラメータの設定\n",
    "\n",
    "# 因子数\n",
    "factors = 300\n",
    "# エポック数\n",
    "n_epochs = 60\n",
    "# windowサイズ\n",
    "window = 500\n",
    "# スキップグラム\n",
    "use_skip_gram = 1\n",
    "# 階層的ソフトマックス\n",
    "use_hierarchial_softmax = 0\n",
    "# 使用する単語の出現回数のしきい値\n",
    "min_count = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item2vecの学習\n",
    "\n",
    "model = gensim.models.word2vec.Word2Vec(\n",
    "    item2vec_data,\n",
    "    vector_size=factors,\n",
    "    window=window,\n",
    "    sg=use_skip_gram,\n",
    "    hs=use_hierarchial_softmax,\n",
    "    epochs=n_epochs,\n",
    "    min_count=min_count,\n",
    ")\n",
    "\n",
    "model.save(f\"{DIR}/i2v_.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## movies.tsvのフィルタリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 00:17:02,130 : INFO : loading Word2Vec object from /home/tenk9/tmuY3S1/MachineLearning/mov_recommend/model/../model/i2v.model\n",
      "2023-09-10 00:17:02,137 : INFO : loading wv recursively from /home/tenk9/tmuY3S1/MachineLearning/mov_recommend/model/../model/i2v.model.wv.* with mmap=None\n",
      "2023-09-10 00:17:02,138 : INFO : setting ignored attribute cum_table to None\n",
      "2023-09-10 00:17:02,191 : INFO : Word2Vec lifecycle event {'fname': '/home/tenk9/tmuY3S1/MachineLearning/mov_recommend/model/../model/i2v.model', 'datetime': '2023-09-10T00:17:02.191561', 'gensim': '4.3.2', 'python': '3.11.3 (main, Apr 19 2023, 23:54:32) [GCC 11.2.0]', 'platform': 'Linux-5.15.90.1-microsoft-standard-WSL2-x86_64-with-glibc2.35', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946\n"
     ]
    }
   ],
   "source": [
    "# movies.tsvがもつ語彙を抽出\n",
    "tsv_cols = [\"movie_id\",\"title\",\"genre\",\"tag\"]\n",
    "movies_tsv_vanilla = pd.read_csv(\n",
    "    f'{DIR}/../data/movies.tsv',\n",
    "    names = tsv_cols,\n",
    "    sep = '\\t',\n",
    "    engine = 'python'\n",
    ")\n",
    "# ヘッダー削除\n",
    "movies_tsv_vanilla = movies_tsv_vanilla.drop(0)\n",
    "# データ型をstr -> intに変換\n",
    "movies_tsv_vanilla['movie_id'] = movies_tsv_vanilla['movie_id'].astype(int)\n",
    "vocab_tsv = set(movies_tsv_vanilla[\"movie_id\"])\n",
    "\n",
    "# モデルの語彙を抽出\n",
    "model = gensim.models.word2vec.Word2Vec.load(f\"{DIR}/../model/i2v.model\")\n",
    "vocab_model = set(model.wv.index_to_key)\n",
    "\n",
    "# 差を取る．tsvの語彙集合の方が大きい．\n",
    "delta = vocab_tsv - vocab_model\n",
    "print(len(delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のように，movies.tsvにはitem2vecの語彙に存在しない映画がある．\n",
    "このため，streamlitで語彙に存在しない映画を選択できてしまう．\n",
    "これを回避するため，movies.tsvを修正する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# modelの語彙に限定する\n",
    "valid_movie_df = movies_tsv_vanilla[movies_tsv_vanilla['movie_id'].isin(vocab_model)]\n",
    "\n",
    "# 整合性確認\n",
    "print(vocab_model == set(valid_movie_df[\"movie_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存\n",
    "valid_movie_df.to_csv(f\"{DIR}/../data/movies_valid.tsv\", sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
